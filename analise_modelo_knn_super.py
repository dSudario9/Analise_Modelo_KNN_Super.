# -*- coding: utf-8 -*-
"""Analise-Modelo KNN Super.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13VwjLQqIPlO600ZRgaJU-AyfCEuYHhAJ
"""

import sklearn  # Import  de Bibliotecas 

#  pip install -U scikit-learn #  Se necessario esse é o comando para instalar a biblioteca atualizada 

import pandas as pd   

import matplotlib.pyplot as plt
import seaborn as sns

import warnings  
warnings.filterwarnings("ignore") #Controle de Aviso .

print(sklearn.__version__)  #Verificar versão

# IMPORTAR DATASER DO COLAB
iris_df = pd.read_csv("/content/iris.csv",index_col=0)  #'index_col=0'  Para eliminar a coluna zero

#iris_df = pd.read_csv("iris.csv") # A função Pandas read_csv() Lê todo o ficheiro de valores separados por vírgulas

iris_df.head()  #Vizualizar dataset

from IPython.display import Image  #Mostrar Imagem do Dataset
Image (filename='/content/iris.png')

#IMPORTA BIBLIOTECAS PARA PLOTAR GRAFICOS 

import plotly.express as px  

# coder#

fig =  px.scatter_3d(iris_df, x=  'sepal length (cm)', y = 'sepal width (cm)', z= 'petal width (cm)',color = 'target_name')

fig.show()

# Criando Modelo 

#importar biblioteca Sklearn
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import  train_test_split

#Separar quais variaveis de entra e variaveis de Saida para alimentar nosso modelo.

X = iris_df.drop(columns=["target_name", "target"])
Y = iris_df[["target"]]

#Modelo de ( test_size=0.3) = trabalhando com   30% dos dados .
#Modelo de Treinamento trabalhando com apenas 70% dos dados random_state=7)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=7)

#Sempre que fazer split é importante confirmar os shape dos modelos de Train e test.
X_train.shape
X_test.shape

y_train.shape
y_test.shape

#Fiz o print apenas para output das respostas .
print(X_train.shape,
X_test.shape
)
print(y_train.shape,
y_test.shape)

#Criando Algoritimo KNN .   

# Criando Variavel para saber qual quantidade de Vizinhos serão escolhidos. =3

K_neighbors = 3

# Criando Classificador  clf - Recebendo parametros (n_neighbors=K_neighbors)

clf = KNeighborsClassifier(n_neighbors=K_neighbors)

#Fim do Modelo ......Agora vamos treinar o Modelo..

# Agora vamos trainar o modelo . 

#Enviando comando para o algoritimo aprender as respostas .

clf.fit(X_train, y_train)

#Verificar e mostrar Predição de Y 
y_pred = clf.predict(X_test)

#Mostrar Dados .. 
y_pred

#Metricar de Acuracia para ver o desempenho do modelo .

#Biblioteca para verificar acuracia . 
from sklearn.metrics import accuracy_score

# Algoritimo de acuracia. 

accuracy_score(y_test, y_pred)*100

#Vamos Criar uma estrutura para verificar qual melhor numero para o modelo KNN...

#Usando um Loop de 3 a 15.
scores_list = []
K_neighbors = range(3, 15)

for k in K_neighbors:
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(X_train, y_train)
  y_pred = knn.predict(X_test)
  scores_list.append(accuracy_score(y_test, y_pred))

# Commented out IPython magic to ensure Python compatibility.
#Biblioteca para plotar grafico .

# %matplotlib inline

import matplotlib.pyplot as plt

plt.plot(K_neighbors, scores_list)
plt.xlabel("Melhor Valor de K")
plt.ylabel("Acuracia")

"""**O nosso modelo de Treinamento mostrou que  o melhor K (KNN)  foi o numero 10  com mais de 95%** Como estamos vendo no Grafico  """